## Como rodar a aplicaÃ§Ã£o

### PrÃ©-requisitos

- docker
- docker-compose
- python (apenas para a ferramenta log_gen)

### Como iniciar o servidor

- Execute `docker compose up --build` para construir e iniciar os contÃªineres.

#### Gerador de Logs

Foi implementado um script em Python para geraÃ§Ã£o de arquivos de log. O script recebe dois parÃ¢metros, sendo o primeiro o nÃºmero de partidas a serem geradas, e o segundo sendo a mÃ©dia de mortes por partida (utilizando uma distribuiÃ§Ã£o normal). O script pode ser executado assim:

```bash
python log_gen.py 1000 50
```

SerÃ¡ produzido um arquivo game_log.txt que pode ser usado para fazer upload na aplicaÃ§Ã£o.

### Acessando os endpoints da aplicaÃ§Ã£o

Arquivos de log podem ser enviados visitando [`GET /`](http://localhost:3000/)
<details>
  <summary><i>Exemplo:</i></summary>
  <img width="1137" height="593" alt="image" src="https://github.com/user-attachments/assets/e27ab504-25d5-473c-8214-d36df8e1cc05" />
</details>

Para visualizar as estatÃ­sticas de uma partida especÃ­fica, basta visitar [`GET /matches/ID_AQUI`](http://localhost:3000/matches/123)
<details>
  <summary><i>Exemplo:</i></summary>
  <img width="1277" height="828" alt="image" src="https://github.com/user-attachments/assets/4fb0719d-29c3-4f3b-9387-2fa99f338a89" />
</details>

Para visualizar estatÃ­sticas globais de todas as partidas jÃ¡ registradas, basta visitar [`GET /matches/`](http://localhost:3000/matches/)
<details>
  <summary><i>Exemplo:</i></summary>
  <img width="1274" height="555" alt="image" src="https://github.com/user-attachments/assets/e74a6747-a9a5-4b2c-9bf3-bd09e8c1ee61" />
</details>


---

## VisÃ£o Geral

Este projeto implementa o desafio tÃ©cnico de anÃ¡lise dos arquivos de log de um jogo de tiro. A soluÃ§Ã£o foi pensada como um pipeline **escalÃ¡vel de ingestÃ£o e anÃ¡lise** desses arquivos de logs.

O sistema Ã© capaz de processar arquivos de log contendo mÃºltiplas partidas, extrai dados estruturados (jogadores, participantes, mortes, partidas) e os persiste em um banco de dados relacional para consultas e anÃ¡lises posteriores.

Foi projetado para lidar com **logs possivelmente grandes** (dezenas ou centenas de milhÃµes de
mortes por arquivo de log) de forma eficiente, utilizando:

- Streams para leitura e escrita de arquivos sem carregÃ¡-los completamente em memÃ³ria.
- DivisÃ£o dos logs em arquivos menores (um por partida).
- Um sistema de filas de **dois nÃ­veis** com BullMQ para escalabilidade e tolerÃ¢ncia a falhas.

---

## Arquitetura

Como mencionado anteriormente, a arquitetura Ã© baseada em um pipeline e possui quatro etapas principais:

1. **Etapa de IngestÃ£o**
   - Usa o `GameLogParser` para ler arquivos de log linha por linha usando streams.
   - Divide o log em chunks, um arquivo por partida, e os escreve no disco tambÃ©m usando streams.
   - Enfileira jobs na fila `match-logs` para processar cada partida individualmente.

2. **Etapa de TransformaÃ§Ã£o dos dados**
   - O `MatchLogParser` lÃª arquivos de partidas individuais como um stream.
   - Extrai informaÃ§Ãµes sobre participantes e mortes.
   - Envia os resultados estruturados para o `MatchService`.

3. **Etapa de PersistÃªncia**
   - Entidades modeladas com TypeORM: `Match`, `Player`, `MatchParticipant` e `Kill`.
   - TransaÃ§Ãµes garantem ingestÃ£o idempotente (segura para retries).
   - InserÃ§Ãµes em bulk garantem mais eficiÃªncia e menos sobrecarga na conexÃ£o com o banco de dados.

4. **Etapa de AnÃ¡lise**
   - O `AnalysisService` serve como uma interface amigÃ¡vel para as anÃ¡lises que o sistema oferece.
   - Todas as anÃ¡lises foram implementadas em queries SQL visando maior performance.
   - EstÃ£o disponÃ­veis as seguintes anÃ¡lises: `GlobalLeaderboard`, `MatchLeaderboard`,
     `MatchFragStreaks`, `MatchNoDeath` e `MatchSpeedKillers`

---

### Sistema de Filas em Dois NÃ­veis

Foi utilizado **BullMQ** com duas filas:

- **Fila `game-logs`**
  ResponsÃ¡vel por jobs de grandes arquivos de log.
  Cada job:
  - Executa o `GameLogParser` para dividir o arquivo em partidas.
  - Enfileira novos jobs na fila `match-logs` (um por partida).

- **Fila `match-logs`**
  ResponsÃ¡vel por jobs de partidas individuais.
  Cada job:
  - Executa o `MatchLogParser` para analisar o arquivo da partida.
  - Persiste os dados no banco via `MatchService`.

#### BenefÃ­cios
- **Escalabilidade**: Um Ãºnico log se divide em mÃºltiplos jobs de partidas processados em paralelo.
- **Isolamento de falhas**: Uma falha ao processar uma partida nÃ£o afeta as demais.
- **Retries**: Pode ser adicionada alguma estratÃ©gia para retries, caso necessÃ¡rio.

Um tempo atrÃ¡s, escrevi sobre esse tipo de soluÃ§Ã£o [neste post](https://medium.com/@luizrogeriocn/improving-rails-scalability-with-better-architecture-c102a2a0cdec) ğŸ‘´

---

### Streams para uso eficiente da memÃ³ria

O sistema usa **streams do Node.js** para processar os logs linha a linha:

- **MemÃ³ria**: O arquivo nunca Ã© carregado inteiro na RAM. Mesmo logs muito grandes podem ser processados.
- **SaÃ­da em chunks**: Cada partida Ã© gravada diretamente em arquivo prÃ³prio via stream.
- **ExtensÃ­vel**: Essa mesma lÃ³gica pode ser adaptada para consumir logs via outros tipos de streams.

Ou seja, o pipeline Ã©  **agnÃ³stico** sobre origem dos dados, o que facilita a adoÃ§Ã£o de outras fontes de
informaÃ§Ã£o, caso seja necessÃ¡rio.

---

### Entidades

Diagrama ER das entidades principais:

```mermaid
erDiagram
    GAME_LOGS {
        uuid id PK
        text url
        enum status
        timestamptz processedAt
        timestamptz createdAt
        timestamptz updatedAt
    }

    MATCHES {
        uuid id PK
        bigint matchIdentifier UK
        timestamptz startedAt
        timestamptz finishedAt
        uuid match_log_id FK
        timestamptz createdAt
        timestamptz updatedAt
    }

    PLAYERS {
        uuid id PK
        varchar name UK
        timestamptz createdAt
        timestamptz updatedAt
    }

    MATCH_PARTICIPANTS {
        uuid id PK
        uuid match_id FK
        uuid player_id FK
        timestamptz createdAt
        timestamptz updatedAt
    }

    KILLS {
        uuid id PK
        uuid killer_match_participant_id FK
        uuid victim_match_participant_id FK
        timestamptz happenedAt
        varchar causeOfDeath
        timestamptz createdAt
        timestamptz updatedAt
    }

    %% Relationships
    GAME_LOGS ||--o{ MATCHES : "has"
    MATCHES ||--o{ MATCH_PARTICIPANTS : "has"
    PLAYERS ||--o{ MATCH_PARTICIPANTS : "joins"
    MATCH_PARTICIPANTS ||--o{ KILLS : "killer"
    MATCH_PARTICIPANTS ||--o{ KILLS : "victim"
```

#### GameLog

Entidade criada, principalmente, para guardar uma referÃªncia para o arquivo de log a ser processado que fica no atributo `url`. Em ambiente de desenvolvimento Ã© utilizado o `LocalStorageService`, que guarda esses arquivos localmente. Mas foi criada uma interface de `storage` numa tentativa de tornar simples a adoÃ§Ã£o de outras implementaÃ§Ãµes para armazenamento como Amazon S3.

Inicialmente havia a ideia de possibilitar a gestÃ£o desses uploads, por isso foram criados os atributos `status` e `processedAt`, mas o suporte Ã  essa funcionalidade nÃ£o chegou a ser implementado.

#### Players

Funciona como uma tabela global de jogadores evitando que haja duplicaÃ§Ã£o desses registros (foram assumidos como Ãºnicos pelo nome).

#### Match

Essa entidade representa uma partida do jogo de tiro que foi processada pela etapa de ingestÃ£o. Possui um identificador externo que foi chamado de `matchId` e os horÃ¡rios de inÃ­cio e tÃ©rmino da partida `startedAt` e `finishedAt`. Foi criado tambÃ©m um campo para relacionamento com o `GameLog` que pode utilizado para fins de depuraÃ§Ã£o em casos de problemas, mas isso nÃ£o foi implementado. Inclusive, durante a ingestÃ£o temos acompanhamento de quais linhas no arquivo original sÃ£o referentes a cada partida e poderÃ­amos tambÃ©m salvar essas informaÃ§Ãµes se fosse necessÃ¡rio.


#### MatchParticipant

Essa entidade representa a participaÃ§Ã£o de um jogador em uma partida (`Player`, `Match`). AlÃ©m disso ela Ã© importante para que possamos fazer o relacionamento mais importante da aplicaÃ§Ã£o: a participaÃ§Ã£o dos jogadores nos eventos de morte das partidas.


#### Kill

A entidade que modela os eventos de morte das partidas. Ela se relaciona com `MatchParticipant` tanto como `killer` quanto como `victim`, permitindo saber quem matou quem. TambÃ©m armazena a causa da morte `causeOfDeath` e o momento em que aconteceu `happenedAt`. Ã‰ importante observar que `killer` pode ser nulo, representando uma morte efetuada pelo mundo.

---

## OrganizaÃ§Ã£o do Projeto

RepresentaÃ§Ã£o de como os diretÃ³rios e arquivos da aplicaÃ§Ã£o estÃ£o organizados:

```
src
â”œâ”€â”€ app.module.ts              # MÃ³dulo raiz da aplicaÃ§Ã£o
â”œâ”€â”€ main.ts                    # Ponto de entrada da aplicaÃ§Ã£o
â”œâ”€â”€ match-domain               # MÃ³dulo de domÃ­nio para funcionalidades das partidas
â”‚   â”œâ”€â”€ analysis               # LÃ³gica de negÃ³cio para anÃ¡lise de resultados das partidas
â”‚   â”‚   â”œâ”€â”€ global-leaderboard.analysis.ts
â”‚   â”‚   â”œâ”€â”€ match-frag-streaks.analysis.ts
â”‚   â”‚   â”œâ”€â”€ match-leaderboard.analysis.ts
â”‚   â”‚   â”œâ”€â”€ match-no-death.analysis.ts
â”‚   â”‚   â”œâ”€â”€ match-speed-killers.analysis.ts
â”‚   â”‚   â””â”€â”€ match-winner.analysis.ts
â”‚   â”œâ”€â”€ controllers             # endpoints HTTP
â”‚   â”‚   â”œâ”€â”€ match.controller.spec.ts
â”‚   â”‚   â””â”€â”€ match.controller.ts
â”‚   â”œâ”€â”€ entities                # Entidades TypeORM que representam tabelas do banco de dados
â”‚   â”‚   â”œâ”€â”€ game-log.entity.ts
â”‚   â”‚   â”œâ”€â”€ kill.entity.ts
â”‚   â”‚   â”œâ”€â”€ match-participant.entity.ts
â”‚   â”‚   â”œâ”€â”€ match.entity.ts
â”‚   â”‚   â””â”€â”€ player.entity.ts
â”‚   â”œâ”€â”€ ingestion               # Parsing e ingestÃ£o de arquivos de log
â”‚   â”‚   â”œâ”€â”€ game-log-parser.spec.ts
â”‚   â”‚   â”œâ”€â”€ game-log-parser.ts
â”‚   â”‚   â”œâ”€â”€ match-log-parser.spec.ts
â”‚   â”‚   â””â”€â”€ match-log-parser.ts
â”‚   â”œâ”€â”€ match-domain.module.ts  # DeclaraÃ§Ã£o do mÃ³dulo de domÃ­nio
â”‚   â”œâ”€â”€ services                # ServiÃ§os da aplicaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ analysis.service.ts
â”‚   â”‚   â”œâ”€â”€ game-log.service.ts
â”‚   â”‚   â”œâ”€â”€ ingestion.service.ts
â”‚   â”‚   â””â”€â”€ match.service.ts
â”‚   â””â”€â”€ workers                 # Workers em background (BullMQ)
â”‚       â”œâ”€â”€ game-logs.processor.ts
â”‚       â””â”€â”€ match-logs.processor.ts
```

---

### Testes

Existem alguns testes unitÃ¡rios para os parsers (`GameLogParser`, `MatchLogParser`) e um teste de "integraÃ§Ã£o entre eles.

Eu planejava escrever a maior parte dos testes em cima das anÃ¡lises das partidas, que considerei como a principal funcionalidade do projeto. PorÃ©m tive muita dificuldade em fazer um banco de dados funcionar de maneira apropriada no ambiente de testes. Investi bastante tempo na tentativa de fazer isso funcionar (adicionar Docker foi uma das tentativas de verificar se o problema era na minha instalaÃ§Ã£o de postgres local). Em determinado momento, consegui ter um banco rodando no ambiente de testes e que fazia rollback das mudanÃ§as ao fim da cada teste (`afterEach`) mas por algum motivo nÃ£o consegui reproduzir esse comportamento consistentemente.

Ainda cogitei tentar fazer mock da conexÃ£o com o banco, porÃ©m percebi que nÃ£o ajudaria muito visto que as anÃ¡lises foram todas implementadas diretamente com SQL. Assim estarÃ­amos mockando justamente o sujeito a ser testado.

EntÃ£o resolvi continuar iterando nos desafios para pelo menos entregar todas as outras coisas que foram pedidas.

---

### Friendly Fire

Essa funcionalidade foi modelada mas nÃ£o chegou a ser implementada. A ideia seria ter um log ligeiramente modifiacado, da seguinte maneira:

```bash
24/04/2020 16:14:22 - New match 11348961 has started
24/04/2020 16:14:22 - Roman joined <TEAM RED>
24/04/2020 16:14:22 - Marcus joined <TEAM BLUE>
24/04/2020 16:14:22 - Jhon joined <TEAM RED>
24/04/2020 16:14:22 - Bryian joined <TEAM RED>
24/04/2020 16:26:12 - Roman killed Marcus using M16
24/04/2020 16:35:56 - Marcus killed Jhon using AK47
24/04/2020 17:12:34 - Roman killed Bryian using M16
24/04/2020 18:26:14 - Bryan killed Marcus using AK47
24/04/2020 19:36:33 - <WORLD> killed Marcus by DROWN
24/04/2020 20:19:22 - Match 11348961 has ended
```

De forma que entre o inÃ­cio do jogo e o primeiro evento de morte, estariam todos os eventos em que os jogadores entram nos times.

EntÃ£o adicionarÃ­amos um atributo `team`, do tipo `string`, em `MatchParticipant` no qual guardarÃ­amos essa informaÃ§Ã£o. Seria necessÃ¡rio modificar o `MatchLogParser` com uma nova regex pra capturar essas linhas e entÃ£o acumulÃ¡-las de forma que seja passado pra o `MatchService` salvar no banco ao executar a funÃ§Ã£o `importMatch`.

---

### Performance

Foram efetuados testes de importaÃ§Ã£o com logs contendo algumas dezenas de milhÃµes de mortes, e o sistema se comportou bem. Continuou responsivo, uma vez que a carga estava toda nos background jobs, e a pÃ¡gina de estatÃ­sticas dos jogos continuou sendo calculada sem atraso.

Nesse cenÃ¡rio, porÃ©m, a pÃ¡gina das estatÃ­sticas globais demorava cerca de 5 segundos para ser calculada. O que jÃ¡ deixa de ser aceitÃ¡vel.

#### Materialized Views

Uma das opÃ§Ãµes para contornar essa degradaÃ§Ã£o de performance, seria ter uma view materializada na qual guardarÃ­amos essas informaÃ§Ãµes jÃ¡ calculadas. E poderÃ­amos definir um intervalo de tempo para atualizaÃ§Ã£o da view, tendo um cron-job para realizar essa tarefa. 

#### Exemplo

<details>
  <summary><i>Tempo para o cÃ¡lculo em uma base com pouco mais de 700.000 `kills` (0.7 segundos):</i></summary>
  <img width="1280" height="798" alt="image" src="https://github.com/user-attachments/assets/9a9f7af1-69a2-4dc1-a272-ff606ef885c6" />
</details>


---

### Logging

Utilizei `console.log` para alguns logs da aplicaÃ§Ã£o. Seria interessante melhorar isso com a introduÃ§Ã£o de uma biblioteca especializada em logs estruturados. Numa pesquisa rÃ¡pida, encontrei uma ferramenta chamada `Winston` que poderia ser utilizada.

---

### Notas Pessoais :)

Primeiramente, gostaria de agradecer a oportunidade de participar desse desafio!

Foi bem interessante e precisei aprender muita coisa nova, uma vez que nÃ£o tinha familiaridade com o
ferramental de Node, TypeScript/JavaScript.

Minha experiÃªncia Ã© majoritariamente em Ruby e Elixir, entÃ£o Ã© possÃ­vel (ou provÃ¡vel) que o cÃ³digo
nÃ£o esteja tÃ£o idiomÃ¡tico. Mas acredito que a maioria dos conceitos que tentei utilizar sejam
intercambiÃ¡veis pra qualquer stack.

Acabei tendo bem mais dificuldade do que eu esperava com a parte de garantir uma conexÃ£o com o banco
de dados, especialmente para os testes. Mas imagino que seja apenas devido Ã  falta de familiaridade
com a forma de fazer isso em aplicaÃ§Ãµes que utilizam as bibliotecas requeridas pelo desafio.

No mais, tentei modelar uma soluÃ§Ã£o eficiente e escalÃ¡vel mas que mantivesse a simplicidade,
facilidade de manutenÃ§Ã£o e de extensÃ£o.

ğŸ‘‹
